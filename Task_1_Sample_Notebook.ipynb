{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "513acd5b",
      "metadata": {
        "id": "513acd5b"
      },
      "source": [
        "\n",
        "# üè• MediaEval-Medico-2025 ‚Äî Subtask 1: GI Image VQA (Colab/T4 Friendly)\n",
        "\n",
        "This notebook fine-tunes **`google/paligemma-3b-pt-224`** on **Kvasir-VQA-x1** using **[ms-swift](https://swift.readthedocs.io/)**, then pushes the result to **Hugging Face Hub**.  \n",
        "It‚Äôs optimized for the **free Colab T4 GPU** tier (‚âà16‚ÄØGB) with 4-bit quantization + LoRA.\n",
        "\n",
        "**Repo:** üåê MediaEval-Medico-2025 ‚Äî https://github.com/simula/MediaEval-Medico-2025\n",
        "\n",
        "\n",
        "**What you‚Äôll get**\n",
        "- ‚úÖ Data prep (images + JSONL suitable for ms-swift VLMs)\n",
        "- ‚úÖ T4-friendly training config (QLoRA + LoRA + checkpointing)\n",
        "- ‚úÖ Validation during training\n",
        "- ‚úÖ Auto-push to Hugging Face Hub\n",
        "- ‚úÖ Minimal inference sanity-check\n",
        "\n",
        "> **Tip:** Tune `num_train_epochs`, batch size, and learning rate based on your GPU memory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ea6cbb3",
      "metadata": {
        "id": "7ea6cbb3"
      },
      "source": [
        "## üîß Runtime & GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4747d8d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4747d8d3",
        "outputId": "9ec008bd-7202-40dd-c032-6be9a63e98d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "PyTorch: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Make sure you're on Colab with GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "import torch, platform, sys, subprocess, json\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Please enable a T4 GPU in Colab runtime.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75f4c40d",
      "metadata": {
        "id": "75f4c40d"
      },
      "source": [
        "## üì¶ Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b061f5ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b061f5ef",
        "outputId": "773ca465-ca61-4531-c025-9aa8326e515d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ms-swift in /usr/local/lib/python3.11/dist-packages (3.7.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.47.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.9.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from ms-swift) (3.12.15)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.0.1)\n",
            "Requirement already satisfied: binpacking in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.5.2)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from ms-swift) (3.4.2)\n",
            "Requirement already satisfied: cpm-kernels in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.0.11)\n",
            "Requirement already satisfied: dacite in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.9.2)\n",
            "Requirement already satisfied: datasets<3.4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (3.3.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.8.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.116.1)\n",
            "Requirement already satisfied: gradio>=3.40.0 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (5.41.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from ms-swift) (8.7.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.42.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from ms-swift) (3.10.0)\n",
            "Requirement already satisfied: modelscope>=1.23 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.28.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from ms-swift) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.0.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.99.1)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.19.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.2.2)\n",
            "Requirement already satisfied: peft<0.17,>=0.11 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ms-swift) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.32.3)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ms-swift) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.2.0)\n",
            "Requirement already satisfied: simplejson>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (3.20.1)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.4.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from ms-swift) (2.19.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from ms-swift) (4.67.1)\n",
            "Requirement already satisfied: transformers<4.56,>=4.33 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (4.55.0)\n",
            "Requirement already satisfied: transformers-stream-generator in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.0.5)\n",
            "Requirement already satisfied: trl<0.21,>=0.15 in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.20.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.35.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from ms-swift) (0.23.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.34.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<3.4,>=3.0->ms-swift) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.4,>=3.0->ms-swift) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.4,>=3.0->ms-swift) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<3.4,>=3.0->ms-swift) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<3.4,>=3.0->ms-swift) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets<3.4,>=3.0->ms-swift) (2024.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets<3.4,>=3.0->ms-swift) (0.34.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (1.1.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (3.11.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio>=3.40.0->ms-swift) (0.16.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio>=3.40.0->ms-swift) (15.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.23->ms-swift) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.23->ms-swift) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ms-swift) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ms-swift) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ms-swift) (2025.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft<0.17,>=0.11->ms-swift) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ms-swift) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ms-swift) (2025.8.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.56,>=4.33->ms-swift) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.56,>=4.33->ms-swift) (0.21.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->ms-swift) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->ms-swift) (1.20.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from attrdict->ms-swift) (1.17.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from binpacking->ms-swift) (1.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->ms-swift) (3.23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ms-swift) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ms-swift) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ms-swift) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ms-swift) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->ms-swift) (3.2.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->ms-swift) (1.5.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->ms-swift) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->ms-swift) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->ms-swift) (1.3.1)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2->ms-swift) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.11/dist-packages (from oss2->ms-swift) (3.23.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2->ms-swift) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2->ms-swift) (2.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ms-swift) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ms-swift) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ms-swift) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ms-swift) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->ms-swift) (3.1.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->ms-swift) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->ms-swift) (43.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio>=3.40.0->ms-swift) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets<3.4,>=3.0->ms-swift) (1.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>=3.40.0->ms-swift) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>=3.40.0->ms-swift) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2->ms-swift) (1.17.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.40.0->ms-swift) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.40.0->ms-swift) (2.19.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2->ms-swift) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.40.0->ms-swift) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ms-swift bitsandbytes wandb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef8138e6",
      "metadata": {
        "id": "ef8138e6"
      },
      "source": [
        "\n",
        "## üîê Authenticate\n",
        "- **Hugging Face**: Required to push your model to Hub. Create a [token](https://huggingface.co/settings/tokens) with `write` scope.\n",
        "- **Weights & Biases (optional)**: Set a project name to log metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7641f6fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7641f6fd",
        "outputId": "9491e541-1233-4559-a120-adda26b43a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `hf auth whoami` to get more information or `hf auth logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: write).\n",
            "The token `Simula` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Simula`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msushantgautam\u001b[0m (\u001b[33mubl\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged into HF as: SushantGautam\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import whoami, login\n",
        "import wandb, os\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "!hf auth login --add-to-git-credential\n",
        "wandb.login()\n",
        "\n",
        "os.environ[\"WANDB_PROJECT\"] = \"Kvasir-VQA-x1_Subtask1\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "HF_USER = whoami()[\"name\"]\n",
        "print(\"Logged into HF as:\", HF_USER)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7163a9db",
      "metadata": {
        "id": "7163a9db"
      },
      "source": [
        "\n",
        "## üóÇÔ∏è Data Preparation (Kvasir-VQA-x1)\n",
        "We‚Äôll:\n",
        "1) Cache all images locally (once) from **`SimulaMet-HOST/Kvasir-VQA`**.  \n",
        "2) Build **VLM-ready JSONL** files (`messages` + `<image>` + `images` path) for **`SimulaMet/Kvasir-VQA-x1`** train/test splits.\n",
        "\n",
        "\n",
        "Remember, you also can add your data augmentation scripts  to augment images  or question, answers here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d0560efe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "e3382a734d634ee5af4dbb7260e7121e",
            "fe6d35b4d69d4cb4b716ee8470badb00",
            "62d0ecddac6e43669a05658dcc36d630",
            "685ea6d2313f4848a10a960dc60bf71f",
            "eb8f71d0b2db4b179a33294972707965",
            "7b4c541981f54d03be356dc68e7abdbb",
            "1a5da5b9fb1b459ab05d7a5f0be13811",
            "3911a2c50d65475fbc82a91974f62b7e",
            "cd9f7274a5304e3d9c598a6d0c9093e5",
            "cc50562977c643ba8c0c62d87653bdbe",
            "1222a551eddc4a86890ec0cb3882c980",
            "06b24ac31c684a7cb2f5d6b0826d79f4",
            "eac502f6331a4ca39fdc8aad2f1aa1b0",
            "66bdc2097b194e1da734b021d483d92d",
            "24534044f9a946aca6f28812ddb11e36",
            "ad5ccd35ae51412fb603dcdfd842dd53",
            "da609776ee7a482b9b0245c4b77c3374",
            "19f3bf261f414dc799a11337faee6ee8",
            "980e9903d6934d488289c543dc26846c",
            "66305123ca2349d28fac0a8f374cf60c",
            "31d643be297144e3bbdb960f8b223d15",
            "da1c44afb9004a27a060ea7d868477ea",
            "30bdb8dae1e4448ea13065b7276c3f00",
            "159a0670c1b047068b49391dc877241c",
            "d462485b02da48668a03ff847ebe54fb",
            "23d05207cb8a477e8b51bb1fd7257a00",
            "571edbf888944e0d9b0592fabe99f7b1",
            "49f1a0502345422fba1c42bd1a273127",
            "f09712e579d9439299544643fd2553f8",
            "98d9eea03b534982ae188af420ba8549",
            "2b438fd697e648208e2d73646152b96a",
            "3cb03766f4b54304a7d8cfa5de6db0cc",
            "2da74e3545ce4f9aab6e4a6a078729d6"
          ]
        },
        "id": "d0560efe",
        "outputId": "8fdf74fa-0287-4001-9020-a9e687718e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dir: Kvasir-VQA-x1\n",
            "Images dir: Kvasir-VQA-x1/images\n",
            "‚è¨ Caching images from SimulaMet-HOST/Kvasir-VQA ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3382a734d634ee5af4dbb7260e7121e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06b24ac31c684a7cb2f5d6b0826d79f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading dataset shards:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30bdb8dae1e4448ea13065b7276c3f00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6500/6500 [01:11<00:00, 91.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating JSONLs ...\n",
            "Train JSONL: Kvasir-VQA-x1/Kvasir-VQA-x1-train.jsonl\n",
            "Test  JSONL: Kvasir-VQA-x1/Kvasir-VQA-x1-test.jsonl\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import json, os\n",
        "\n",
        "# Working directories\n",
        "BASE_DIR = Path(\"./\")\n",
        "DATA_DIR = BASE_DIR / \"Kvasir-VQA-x1\"\n",
        "IMG_DIR  = DATA_DIR / \"images\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Data dir:\", DATA_DIR)\n",
        "print(\"Images dir:\", IMG_DIR)\n",
        "\n",
        "# 1) Save unique images locally\n",
        "print(\"‚è¨ Caching images from SimulaMet-HOST/Kvasir-VQA ...\")\n",
        "host = load_dataset(\"SimulaMet-HOST/Kvasir-VQA\", split=\"raw\")\n",
        "df = host.select_columns(['source', 'question', 'answer', 'img_id']).to_pandas()\n",
        "# Save one image per unique img_id\n",
        "for i, row in tqdm(df.groupby('img_id').nth(0).iterrows(), total=df['img_id'].nunique()):\n",
        "    p = IMG_DIR / f\"{row['img_id']}.jpg\"\n",
        "    if p.exists():\n",
        "        continue\n",
        "    host[i]['image'].save(p)\n",
        "\n",
        "# 2) Create JSONLs for train/test from Kvasir-VQA-x1 (VLM-ready for ms-swift)\n",
        "print(\"Creating JSONLs ...\")\n",
        "def write_jsonl(split):\n",
        "    out_path = DATA_DIR / f\"Kvasir-VQA-x1-{split}.jsonl\"\n",
        "    ds = load_dataset(\"SimulaMet/Kvasir-VQA-x1\", split=split)\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for r in ds:\n",
        "            rec = {\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"user\", \"content\": f\"<image>{r['question']}\"},\n",
        "                    {\"role\": \"assistant\", \"content\": r[\"answer\"]}\n",
        "                ],\n",
        "                \"images\": [str(IMG_DIR / f\"{r['img_id']}.jpg\")]\n",
        "            }\n",
        "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "    return out_path\n",
        "\n",
        "train_jsonl = write_jsonl(\"train\")\n",
        "test_jsonl  = write_jsonl(\"test\")\n",
        "\n",
        "print(\"Train JSONL:\", train_jsonl)\n",
        "print(\"Test  JSONL:\", test_jsonl)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2127d7eb",
      "metadata": {
        "id": "2127d7eb"
      },
      "source": [
        "### üîç Quick sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "965bd07e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "965bd07e",
        "outputId": "0520a6d4-3416-4608-ea9a-d95604c11b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 1 ---\n",
            "messages: [{'role': 'user', 'content': '<image>Are there any abnormalities, polyps, or anatomical landmarks visible in the image?'}, {'role': 'assistant', 'content': 'Evidence of oesophagitis is present with no polyps identified and the z-line is visible.'}]\n",
            "images: ['Kvasir-VQA-x1/images/clb0kvxvm90y4074yf50vf5nq.jpg']\n",
            "\n",
            "--- Sample 2 ---\n",
            "messages: [{'role': 'user', 'content': '<image>What procedure is depicted in the image and what type of polyp is observed?'}, {'role': 'assistant', 'content': 'Evidence of a colonoscopy with a paris iia polyp noted'}]\n",
            "images: ['Kvasir-VQA-x1/images/cl8k2u1r71foz083278j63qnm.jpg']\n",
            "\n",
            "--- Sample 3 ---\n",
            "messages: [{'role': 'user', 'content': '<image>Have all polyps been removed, is there any text present, and where is the abnormality located in the image?'}, {'role': 'assistant', 'content': 'Polyps remain present, text is visible, and the abnormality is located in the central and upper-center regions.'}]\n",
            "images: ['Kvasir-VQA-x1/images/cl8k2u1qa1ekz08324rek2qcv.jpg']\n",
            "\n",
            "Looks good ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "import json, itertools\n",
        "from pathlib import Path\n",
        "\n",
        "sample_lines = list(itertools.islice(open(train_jsonl, \"r\", encoding=\"utf-8\"), 3))\n",
        "for i, line in enumerate(sample_lines, 1):\n",
        "    j = json.loads(line)\n",
        "    print(f\"\\n--- Sample {i} ---\")\n",
        "    print(\"messages:\", j[\"messages\"])\n",
        "    print(\"images:\", j[\"images\"])\n",
        "    assert Path(j[\"images\"][0]).exists(), \"Missing image file!\"\n",
        "print(\"\\nLooks good ‚úÖ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö†Ô∏è ‚ö†Ô∏è ‚ö†Ô∏è  \n",
        "To reduce validation time, we randomly sampled 1,000 entries from the full test set using the shuf command:"
      ],
      "metadata": {
        "id": "X3Br3uwxEge7"
      },
      "id": "X3Br3uwxEge7"
    },
    {
      "cell_type": "code",
      "source": [
        "!shuf -n 1000 Kvasir-VQA-x1/Kvasir-VQA-x1-test.jsonl > Kvasir-VQA-x1/Kvasir-VQA-x1-test-1000.jsonl\n",
        "VAL_1000_PATH= \"Kvasir-VQA-x1/Kvasir-VQA-x1-test-1000.jsonl\""
      ],
      "metadata": {
        "id": "4JBUv5xjEYYi"
      },
      "id": "4JBUv5xjEYYi",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üöÄ Fine-tune PaliGemma 3B (QLoRA + LoRA)\n",
        "> You can also use any other multimodal models listed here:  \n",
        "> https://swift.readthedocs.io/en/latest/Instruction/Supported-models-and-datasets.html"
      ],
      "metadata": {
        "id": "iB0nDX4qDKFU"
      },
      "id": "iB0nDX4qDKFU"
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME=\"google/paligemma-3b-pt-224\" ## you can choose this from the link above\n",
        "# Your target Huggingface repo name (can change as required!)\n",
        "HUB_MODEL_ID = f\"Kvasir-VQA-x1-lora_{datetime.now().strftime('%y%m%d-%H%M')}\" # appends date time at end\n",
        "\n",
        "TRAIN_PATH=str(train_jsonl)\n",
        "VAL_PATH=str(test_jsonl)\n",
        "\n",
        "print(\"Model:      \", MODEL_NAME)\n",
        "print(\"Train file: \", TRAIN_PATH)\n",
        "print(\"Valid file: \", VAL_PATH)\n",
        "print(\"Hub repo:   \", HUB_MODEL_ID)\n",
        "\n",
        "print(\"üìù You can find training logs after the training starts at: https://wandb.ai/home\")\n",
        "print(\"üìå After each validation stage, the HF repository will be updated with the best model.\")\n",
        "print(f\"‚úÖ Model will be available at: https://huggingface.co/{HF_USER}/{HUB_MODEL_ID}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VdkrDgcDGeJ",
        "outputId": "9abdd147-3b03-4e4e-c58a-bcfe7319a10a"
      },
      "id": "_VdkrDgcDGeJ",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:       google/paligemma-3b-pt-224\n",
            "Train file:  Kvasir-VQA-x1/Kvasir-VQA-x1-train.jsonl\n",
            "Valid file:  Kvasir-VQA-x1/Kvasir-VQA-x1-test.jsonl\n",
            "Hub repo:    Kvasir-VQA-x1-lora_250812-1155\n",
            "üìù You can find training logs after the training starts at: https://wandb.ai/home\n",
            "üìå After each validation stage, the HF repository will be updated with the best model.\n",
            "‚úÖ Model will be available at: https://huggingface.co/SushantGautam/Kvasir-VQA-x1-lora_250812-1155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf520529",
      "metadata": {
        "id": "bf520529"
      },
      "source": [
        "\n",
        "T4-friendly defaults for 3B:\n",
        "- `bnb` 4-bit quantization (nf4 + double quant)\n",
        "- `per_device_train_batch_size=4` (adjust if OOM)\n",
        "- `gradient_accumulation_steps=4` (effective batch ‚âà16)\n",
        "- `freeze_vit=true`, `gradient_checkpointing=true`\n",
        "\n",
        "> Increase batch size and/or `num_train_epochs` if you have more VRAM.\n",
        "\n",
        "See https://swift.readthedocs.io/en/latest/Instruction/Command-line-parameters.html for all supported training parameters. Play with them to get the best results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e137b4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e137b4c",
        "outputId": "f1765eac-c4a5-4ecf-e9bb-1b8fae8f9459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run sh: `/usr/bin/python3 /usr/local/lib/python3.11/dist-packages/swift/cli/sft.py --dataset Kvasir-VQA-x1/Kvasir-VQA-x1-train.jsonl --val_dataset Kvasir-VQA-x1/Kvasir-VQA-x1-test-1000.jsonl --model google/paligemma-3b-pt-224 --max_length 512 --train_type lora --torch_dtype float16 --quant_method bnb --quant_bits 4 --bnb_4bit_compute_dtype float16 --bnb_4bit_quant_type nf4 --bnb_4bit_use_double_quant true --num_train_epochs 1 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 4 --learning_rate 2e-5 --lr_scheduler_type linear --warmup_ratio 0.03 --weight_decay 0.01 --lora_rank 16 --lora_alpha 32 --freeze_vit true --gradient_checkpointing true --load_best_model_at_end True --metric_for_best_model eval_token_acc --greater_is_better True --save_steps 1000 --save_total_limit 2 --logging_steps 20 --output_dir output_Kvasir-VQA-x1 --use_hf true --push_to_hub true --hub_model_id Kvasir-VQA-x1-lora_250812-1155 --report_to wandb --dataloader_num_workers 2 --dataset_num_proc 2`\n",
            "2025-08-12 11:57:48.368611: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754999868.650195   59632 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754999868.732841   59632 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754999869.252275   59632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754999869.252318   59632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754999869.252323   59632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754999869.252331   59632 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-12 11:57:49.299111: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO:swift] Successfully registered `/usr/local/lib/python3.11/dist-packages/swift/llm/dataset/data/dataset_info.json`.\n",
            "[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: google/paligemma-3b-pt-224\n",
            "Fetching 11 files: 100% 11/11 [00:00<00:00, 118300.88it/s]\n",
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--google--paligemma-3b-pt-224/snapshots/35e4f46485b4d07967e7e9935bc3786aad50687c\n",
            "[INFO:swift] Because len(args.val_dataset) > 0, setting split_dataset_ratio: 0.0\n",
            "[INFO:swift] Setting args.lazy_tokenize: True\n",
            "[INFO:swift] output_dir: /content/output_Kvasir-VQA-x1/v3-20250812-115800\n",
            "[INFO:swift] Global seed set to 42\n",
            "[INFO:swift] args: TrainArguments(\n",
            "_n_gpu=-1,\n",
            "acc_strategy=token,\n",
            "accelerator_config={'dispatch_batches': False},\n",
            "adafactor=False,\n",
            "adalora_beta1=0.85,\n",
            "adalora_beta2=0.85,\n",
            "adalora_deltaT=1,\n",
            "adalora_init_r=12,\n",
            "adalora_orth_reg_weight=0.5,\n",
            "adalora_target_r=8,\n",
            "adalora_tfinal=0,\n",
            "adalora_tinit=0,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.95,\n",
            "adam_epsilon=1e-08,\n",
            "adapter_act=gelu,\n",
            "adapter_length=128,\n",
            "adapters=[],\n",
            "add_version=True,\n",
            "agent_template=None,\n",
            "aligner_lr=None,\n",
            "attn_impl=None,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "bnb_4bit_compute_dtype=torch.float16,\n",
            "bnb_4bit_quant_storage=None,\n",
            "bnb_4bit_quant_type=nf4,\n",
            "bnb_4bit_use_double_quant=True,\n",
            "boft_block_num=0,\n",
            "boft_block_size=4,\n",
            "boft_dropout=0.0,\n",
            "boft_n_butterfly_factor=1,\n",
            "cached_dataset=[],\n",
            "channels=None,\n",
            "check_model=True,\n",
            "ckpt_dir=None,\n",
            "columns={},\n",
            "create_checkpoint_symlink=False,\n",
            "custom_dataset_info=[],\n",
            "custom_register_path=[],\n",
            "data_seed=42,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=2,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset=['Kvasir-VQA-x1/Kvasir-VQA-x1-train.jsonl'],\n",
            "dataset_num_proc=2,\n",
            "dataset_shuffle=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=18000000,\n",
            "debug=None,\n",
            "deepspeed=None,\n",
            "deepspeed_autotp_size=None,\n",
            "device_map=None,\n",
            "disable_tqdm=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "download_mode=reuse_dataset_if_exists,\n",
            "ds3_gather_for_generation=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_dataset=[],\n",
            "eval_dataset_args=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_generation_config=None,\n",
            "eval_limit=None,\n",
            "eval_on_start=False,\n",
            "eval_steps=1000.0,\n",
            "eval_strategy=steps,\n",
            "eval_use_evalscope=False,\n",
            "eval_use_gather_object=False,\n",
            "external_plugins=[],\n",
            "fourier_n_frequency=2000,\n",
            "fourier_scaling=300.0,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "freeze_aligner=True,\n",
            "freeze_llm=False,\n",
            "freeze_parameters=[],\n",
            "freeze_parameters_ratio=0.0,\n",
            "freeze_parameters_regex=None,\n",
            "freeze_vit=True,\n",
            "fsdp=,\n",
            "fsdp_config=None,\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "galore_cos_threshold=0.4,\n",
            "galore_gamma_proj=2,\n",
            "galore_optim_per_parameter=False,\n",
            "galore_proj_bits=4,\n",
            "galore_proj_group_size=256,\n",
            "galore_proj_quant=False,\n",
            "galore_proj_type=std,\n",
            "galore_quantization=False,\n",
            "galore_queue_size=5,\n",
            "galore_rank=128,\n",
            "galore_scale=1.0,\n",
            "galore_target_modules=None,\n",
            "galore_update_proj_gap=50,\n",
            "galore_with_embedding=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hqq_axis=None,\n",
            "hub_always_push=False,\n",
            "hub_model_id=Kvasir-VQA-x1-lora_250812-1155,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_args_error=False,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "init_strategy=None,\n",
            "init_weights=True,\n",
            "interleave_prob=None,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "lazy_tokenize=True,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "lisa_activated_layers=0,\n",
            "lisa_step_interval=20,\n",
            "llamapro_num_groups=None,\n",
            "llamapro_num_new_blocks=4,\n",
            "load_args=False,\n",
            "load_best_model_at_end=True,\n",
            "load_data_args=False,\n",
            "load_from_cache_file=True,\n",
            "local_rank=-1,\n",
            "local_repo_path=None,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/output_Kvasir-VQA-x1/v3-20250812-115800/runs,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=20,\n",
            "logging_strategy=steps,\n",
            "logprobs=False,\n",
            "lora_alpha=32,\n",
            "lora_bias=none,\n",
            "lora_dropout=0.05,\n",
            "lora_dtype=None,\n",
            "lora_ga_batch_size=2,\n",
            "lora_ga_direction=ArB2r,\n",
            "lora_ga_iters=2,\n",
            "lora_ga_max_length=1024,\n",
            "lora_ga_scale=stable,\n",
            "lora_ga_stable_gamma=16,\n",
            "lora_modules=[],\n",
            "lora_rank=16,\n",
            "lorap_lr_ratio=None,\n",
            "loss_scale=default,\n",
            "loss_type=None,\n",
            "lr_scheduler_kwargs=None,\n",
            "lr_scheduler_type=linear,\n",
            "max_epochs=None,\n",
            "max_grad_norm=1.0,\n",
            "max_length=512,\n",
            "max_memory={},\n",
            "max_model_len=None,\n",
            "max_new_tokens=64,\n",
            "max_pixels=None,\n",
            "max_steps=-1,\n",
            "metric=None,\n",
            "metric_for_best_model=eval_token_acc,\n",
            "model=google/paligemma-3b-pt-224,\n",
            "model_author=None,\n",
            "model_kwargs={},\n",
            "model_name=None,\n",
            "model_revision=None,\n",
            "model_type=paligemma,\n",
            "modules_to_save=[],\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "new_special_tokens=[],\n",
            "no_cuda=False,\n",
            "norm_bbox=None,\n",
            "num_beams=1,\n",
            "num_labels=None,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "optimizer=None,\n",
            "output_dir=/content/output_Kvasir-VQA-x1/v3-20250812-115800,\n",
            "overwrite_output_dir=False,\n",
            "packing=False,\n",
            "padding_free=False,\n",
            "padding_side=right,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "problem_type=None,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "quant_bits=4,\n",
            "quant_method=bnb,\n",
            "ray_scope=last,\n",
            "reft_args=None,\n",
            "reft_intervention_type=LoreftIntervention,\n",
            "reft_layer_key=None,\n",
            "reft_layers=None,\n",
            "reft_rank=4,\n",
            "remove_unused_columns=True,\n",
            "repetition_penalty=None,\n",
            "report_to=['wandb'],\n",
            "response_prefix=None,\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "resume_only_model=False,\n",
            "rope_scaling=None,\n",
            "router_aux_loss_coef=None,\n",
            "run_name=/content/output_Kvasir-VQA-x1/v3-20250812-115800,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=1000.0,\n",
            "save_strategy=steps,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "sequence_parallel_size=1,\n",
            "shuffle_buffer_size=1000,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_dataset_ratio=0.0,\n",
            "stop_words=[],\n",
            "stopping_strategy=first_exhausted,\n",
            "stream=False,\n",
            "streaming=False,\n",
            "strict=False,\n",
            "swanlab_exp_name=None,\n",
            "swanlab_lark_secret=None,\n",
            "swanlab_lark_webhook_url=None,\n",
            "swanlab_mode=cloud,\n",
            "swanlab_project=None,\n",
            "swanlab_token=<SWANLAB_TOKEN>,\n",
            "swanlab_workspace=None,\n",
            "system=None,\n",
            "target_modules=['all-linear'],\n",
            "target_regex=None,\n",
            "task_type=causal_lm,\n",
            "temperature=0.0,\n",
            "template=paligemma,\n",
            "template_backend=swift,\n",
            "tf32=None,\n",
            "top_k=None,\n",
            "top_logprobs=None,\n",
            "top_p=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_dtype=torch.float16,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "train_dataloader_shuffle=True,\n",
            "train_type=lora,\n",
            "trainable_parameters=[],\n",
            "trainable_parameters_regex=None,\n",
            "truncation_strategy=delete,\n",
            "tuner_backend=peft,\n",
            "use_chat_template=True,\n",
            "use_cpu=False,\n",
            "use_dora=False,\n",
            "use_galore=False,\n",
            "use_hf=True,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_logits_to_keep=None,\n",
            "use_mps_device=False,\n",
            "use_rslora=False,\n",
            "use_swift_lora=False,\n",
            "val_dataset=['Kvasir-VQA-x1/Kvasir-VQA-x1-test-1000.jsonl'],\n",
            "val_dataset_shuffle=False,\n",
            "vera_d_initial=0.1,\n",
            "vera_dropout=0.0,\n",
            "vera_projection_prng_key=0,\n",
            "vera_rank=256,\n",
            "vit_gradient_checkpointing=None,\n",
            "vit_lr=None,\n",
            "warmup_ratio=0.03,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            "zero_hpz_partition_size=None,\n",
            ")\n",
            "[INFO:swift] Downloading the model from HuggingFace Hub, model_id: google/paligemma-3b-pt-224\n",
            "Fetching 14 files: 100% 14/14 [00:00<00:00, 15021.81it/s]\n",
            "[INFO:swift] Loading the model using model_dir: /root/.cache/huggingface/hub/models--google--paligemma-3b-pt-224/snapshots/35e4f46485b4d07967e7e9935bc3786aad50687c\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "[INFO:swift] model_kwargs: {'device_map': 'cuda:0', 'quantization_config': BitsAndBytesConfig {\n",
            "  \"_load_in_4bit\": true,\n",
            "  \"_load_in_8bit\": false,\n",
            "  \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "  \"bnb_4bit_quant_type\": \"nf4\",\n",
            "  \"bnb_4bit_use_double_quant\": true,\n",
            "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "  \"llm_int8_has_fp16_weight\": false,\n",
            "  \"llm_int8_skip_modules\": [\n",
            "    \"model.vision_tower\",\n",
            "    \"model.multi_modal_projector\",\n",
            "    \"lm_head\"\n",
            "  ],\n",
            "  \"llm_int8_threshold\": 6.0,\n",
            "  \"load_in_4bit\": true,\n",
            "  \"load_in_8bit\": false,\n",
            "  \"quant_method\": \"bitsandbytes\"\n",
            "}\n",
            "}\n",
            "Loading checkpoint shards: 100% 3/3 [01:03<00:00, 21.06s/it]\n",
            "[INFO:swift] model.hf_device_map: {'': device(type='cuda', index=0)}\n",
            "[INFO:swift] model_info: ModelInfo(model_type='paligemma', model_dir='/root/.cache/huggingface/hub/models--google--paligemma-3b-pt-224/snapshots/35e4f46485b4d07967e7e9935bc3786aad50687c', torch_dtype=torch.float16, max_model_len=8192, quant_method='bnb', quant_bits=4, rope_scaling=None, is_moe_model=False, config=PaliGemmaConfig {\n",
            "  \"architectures\": [\n",
            "    \"PaliGemmaForConditionalGeneration\"\n",
            "  ],\n",
            "  \"bos_token_id\": 2,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"ignore_index\": -100,\n",
            "  \"image_token_index\": 257152,\n",
            "  \"model_type\": \"paligemma\",\n",
            "  \"pad_token_id\": 0,\n",
            "  \"projection_dim\": 2048,\n",
            "  \"quantization_config\": {\n",
            "    \"_load_in_4bit\": true,\n",
            "    \"_load_in_8bit\": false,\n",
            "    \"bnb_4bit_compute_dtype\": \"float16\",\n",
            "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "    \"bnb_4bit_quant_type\": \"nf4\",\n",
            "    \"bnb_4bit_use_double_quant\": true,\n",
            "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "    \"llm_int8_has_fp16_weight\": false,\n",
            "    \"llm_int8_skip_modules\": [\n",
            "      \"model.vision_tower\",\n",
            "      \"model.multi_modal_projector\",\n",
            "      \"lm_head\"\n",
            "    ],\n",
            "    \"llm_int8_threshold\": 6.0,\n",
            "    \"load_in_4bit\": true,\n",
            "    \"load_in_8bit\": false,\n",
            "    \"quant_method\": \"bitsandbytes\"\n",
            "  },\n",
            "  \"text_config\": {\n",
            "    \"attention_bias\": false,\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"head_dim\": 256,\n",
            "    \"hidden_act\": \"gelu_pytorch_tanh\",\n",
            "    \"hidden_activation\": null,\n",
            "    \"hidden_size\": 2048,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 16384,\n",
            "    \"max_position_embeddings\": 8192,\n",
            "    \"model_type\": \"gemma\",\n",
            "    \"num_attention_heads\": 8,\n",
            "    \"num_hidden_layers\": 18,\n",
            "    \"num_image_tokens\": 256,\n",
            "    \"num_key_value_heads\": 1,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"rope_theta\": 10000.0,\n",
            "    \"torch_dtype\": \"float16\",\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 257216\n",
            "  },\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.55.0\",\n",
            "  \"vision_config\": {\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"hidden_act\": \"gelu_pytorch_tanh\",\n",
            "    \"hidden_size\": 1152,\n",
            "    \"image_size\": 224,\n",
            "    \"intermediate_size\": 4304,\n",
            "    \"layer_norm_eps\": 1e-06,\n",
            "    \"model_type\": \"siglip_vision_model\",\n",
            "    \"num_attention_heads\": 16,\n",
            "    \"num_channels\": 3,\n",
            "    \"num_hidden_layers\": 27,\n",
            "    \"num_image_tokens\": 256,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"patch_size\": 14,\n",
            "    \"projection_dim\": 2048,\n",
            "    \"projector_hidden_act\": \"gelu_fast\",\n",
            "    \"torch_dtype\": \"float16\",\n",
            "    \"vision_use_head\": false\n",
            "  }\n",
            "}\n",
            ", task_type='causal_lm', num_labels=None)\n",
            "[INFO:swift] model.generation_config: GenerationConfig {\n",
            "  \"bos_token_id\": 2,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"max_new_tokens\": 64,\n",
            "  \"pad_token_id\": 0\n",
            "}\n",
            "\n",
            "[INFO:swift] default_system: None\n",
            "[INFO:swift] max_length: 512\n",
            "[INFO:swift] response_prefix: ''\n",
            "[INFO:swift] agent_template: react_en\n",
            "[INFO:swift] norm_bbox: norm1000\n",
            "[INFO:swift] Start time of running main: 2025-08-12 11:59:08.213105\n",
            "[INFO:swift] swift.__version__: 3.7.0\n",
            "Setting num_proc from 2 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 2 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 143594 examples [00:00, 255230.73 examples/s]\n",
            "Map (num_proc=2): 100% 143594/143594 [00:07<00:00, 19451.85 examples/s]\n",
            "Setting num_proc from 2 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 2 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 1000 examples [00:00, 161493.30 examples/s]\n",
            "Map (num_proc=2): 100% 1000/1000 [00:00<00:00, 3557.24 examples/s]\n",
            "[INFO:swift] train_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 143594\n",
            "})\n",
            "[INFO:swift] val_dataset: Dataset({\n",
            "    features: ['messages', 'images'],\n",
            "    num_rows: 1000\n",
            "})\n",
            "[INFO:swift] [INPUT_IDS] [257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 257152, 2, 1841, 10286, 603, 47596, 575, 573, 2416, 235336, 108, 92323, 576, 11307, 111601, 10286, 1]\n",
            "[INFO:swift] [INPUT] [257152 * 256]<bos>What procedure is depicted in the image?\n",
            "evidence of colonoscopy procedure<eos>\n",
            "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 92323, 576, 11307, 111601, 10286, 1]\n",
            "[INFO:swift] [LABELS] [-100 * 266]evidence of colonoscopy procedure<eos>\n",
            "[INFO:swift] The TrainArguments will be saved in: /content/output_Kvasir-VQA-x1/v3-20250812-115800/args.json\n",
            "[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/root/.cache/huggingface/hub/models--google--paligemma-3b-pt-224/snapshots/35e4f46485b4d07967e7e9935bc3786aad50687c', revision=None, inference_mode=False, r=16, target_modules='^(model.language_model.*\\\\.(k_proj|gate_proj|q_proj|down_proj|up_proj|v_proj|o_proj))$', exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
            "[INFO:swift] model: PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): PaliGemmaForConditionalGeneration(\n",
            "      (model): PaliGemmaModel(\n",
            "        (vision_tower): SiglipVisionModel(\n",
            "          (vision_model): SiglipVisionTransformer(\n",
            "            (embeddings): SiglipVisionEmbeddings(\n",
            "              (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
            "              (position_embedding): Embedding(256, 1152)\n",
            "            )\n",
            "            (encoder): SiglipEncoder(\n",
            "              (layers): ModuleList(\n",
            "                (0-26): 27 x SiglipEncoderLayer(\n",
            "                  (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
            "                  (self_attn): SiglipAttention(\n",
            "                    (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
            "                    (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
            "                    (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
            "                    (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
            "                  )\n",
            "                  (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
            "                  (mlp): SiglipMLP(\n",
            "                    (activation_fn): PytorchGELUTanh()\n",
            "                    (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
            "                    (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "        (multi_modal_projector): PaliGemmaMultiModalProjector(\n",
            "          (linear): Linear(in_features=1152, out_features=2048, bias=True)\n",
            "        )\n",
            "        (language_model): GemmaModel(\n",
            "          (embed_tokens): Embedding(257216, 2048, padding_idx=0)\n",
            "          (layers): ModuleList(\n",
            "            (0-17): 18 x GemmaDecoderLayer(\n",
            "              (self_attn): GemmaAttention(\n",
            "                (q_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (k_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (v_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=256, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (o_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "              )\n",
            "              (mlp): GemmaMLP(\n",
            "                (gate_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=16384, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (up_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=2048, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=16384, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (down_proj): lora.Linear4bit(\n",
            "                  (base_layer): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
            "                  (lora_dropout): ModuleDict(\n",
            "                    (default): Dropout(p=0.05, inplace=False)\n",
            "                  )\n",
            "                  (lora_A): ModuleDict(\n",
            "                    (default): Linear(in_features=16384, out_features=16, bias=False)\n",
            "                  )\n",
            "                  (lora_B): ModuleDict(\n",
            "                    (default): Linear(in_features=16, out_features=2048, bias=False)\n",
            "                  )\n",
            "                  (lora_embedding_A): ParameterDict()\n",
            "                  (lora_embedding_B): ParameterDict()\n",
            "                  (lora_magnitude_vector): ModuleDict()\n",
            "                )\n",
            "                (act_fn): PytorchGELUTanh()\n",
            "              )\n",
            "              (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "              (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "            )\n",
            "          )\n",
            "          (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "          (rotary_emb): GemmaRotaryEmbedding()\n",
            "        )\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2048, out_features=257216, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[INFO:swift] model_parameter_info: PeftModelForCausalLM: 1952.1738M Params (19.6116M Trainable [1.0046%]), 0.0004M Buffers.\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=2, read=1, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.modelscope.cn', port=443): Read timed out. (read timeout=0.5)\")': /api/v1/models/unknown/revisions\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=2, read=0, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.modelscope.cn', port=443): Read timed out. (read timeout=0.5)\")': /api/v1/models/unknown/revisions\n",
            "/usr/local/lib/python3.11/dist-packages/swift/trainers/mixin.py:94: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(\n",
            "[INFO:swift] use_reentrant: True\n",
            "[INFO:swift] The logging file will be saved in: /content/output_Kvasir-VQA-x1/v3-20250812-115800/logging.jsonl\n",
            "[INFO:swift] Successfully registered post_encode hook: ['PeftModelForCausalLM'].\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msushantgautam\u001b[0m (\u001b[33mubl\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250812_115927-qkc22fwd\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m/content/output_Kvasir-VQA-x1/v3-20250812-115800\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ubl/Kvasir-VQA-x1_Subtask1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ubl/Kvasir-VQA-x1_Subtask1/runs/qkc22fwd\u001b[0m\n",
            "Train:   0% 0/8975 [00:00<?, ?it/s][INFO:swift] use_logits_to_keep: False\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "{'loss': 3.49173903, 'token_acc': 0.32659933, 'grad_norm': 3.88380671, 'learning_rate': 7e-08, 'memory(GiB)': 11.34, 'train_speed(iter/s)': 0.083585, 'epoch': 0.0, 'global_step/max_steps': '1/8975', 'percentage': '0.01%', 'elapsed_time': '9s', 'remaining_time': '23h 38m 54s'}\n",
            "Train:   0% 15/8975 [01:41<16:43:21,  6.72s/it]"
          ]
        }
      ],
      "source": [
        "# training command\n",
        "# can also use full validation set in --val_dataset with \"VAL_PATH\"\n",
        "!swift sft \\\n",
        "--dataset \"$TRAIN_PATH\" \\\n",
        "--val_dataset \"$VAL_1000_PATH\" \\\n",
        "--model \"$MODEL_NAME\" \\\n",
        "--max_length 512 \\\n",
        "--train_type lora \\\n",
        "--torch_dtype float16 \\\n",
        "--quant_method bnb --quant_bits 4 \\\n",
        "--bnb_4bit_compute_dtype float16 \\\n",
        "--bnb_4bit_quant_type nf4 \\\n",
        "--bnb_4bit_use_double_quant true \\\n",
        "--num_train_epochs 1 \\\n",
        "--per_device_train_batch_size 4 \\\n",
        "--per_device_eval_batch_size 4 \\\n",
        "--gradient_accumulation_steps 4 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--lr_scheduler_type linear \\\n",
        "--warmup_ratio 0.03 \\\n",
        "--weight_decay 0.01 \\\n",
        "--lora_rank 16 --lora_alpha 32 \\\n",
        "--freeze_vit true \\\n",
        "--gradient_checkpointing true \\\n",
        "--load_best_model_at_end True \\\n",
        "--metric_for_best_model eval_token_acc \\\n",
        "--greater_is_better True \\\n",
        "--save_steps 1000 \\\n",
        "--save_total_limit 2 \\\n",
        "--logging_steps 20 \\\n",
        "--output_dir output_Kvasir-VQA-x1 \\\n",
        "--use_hf true \\\n",
        "--push_to_hub true \\\n",
        "--hub_token  \"$(cat ~/.cache/huggingface/token)\" \\\n",
        "--hub_model_id \"$HUB_MODEL_ID\" \\\n",
        "--report_to wandb \\\n",
        "--dataloader_num_workers 2 \\\n",
        "--dataset_num_proc 2 \\\n",
        "# --resume_from_checkpoint output_Kvasir-VQA-x1/checkpoint-<LAST_STEP>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e5ce416",
      "metadata": {
        "id": "5e5ce416"
      },
      "source": [
        "\n",
        "## üî¨ Inference Sanity Check\n",
        "Load the LoRA-adapted model via `swift infer` on a couple of samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd40d52a",
      "metadata": {
        "id": "cd40d52a"
      },
      "outputs": [],
      "source": [
        "from swift.llm import PtEngine, RequestConfig, InferRequest\n",
        "import json, random\n",
        "from PIL import Image\n",
        "\n",
        "import torch, gc # clean mem\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "\n",
        "ADAPTERS = f\"{HF_USER}/{HUB_MODEL_ID}\"\n",
        "print(f\"Try to load model from: https://huggingface.co/{ADAPTERS} as an adapter to {MODEL_NAME}\")\n",
        "engine = PtEngine(model_id_or_path=MODEL_NAME, adapters=f\"{ADAPTERS}\", max_batch_size=2, use_hf=True, model_type=\"paligemma\")\n",
        "# adapters=XXXX should be  your huggingface repo saved from the training process above like \"SushantGautam/Kvasir-VQA-x1-lora-XXXX\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SAMPLES = 10\n",
        "\n",
        "rcfg = RequestConfig(max_tokens=64, temperature=0)\n",
        "gc.collect(); torch.cuda.empty_cache(); torch.cuda.ipc_collect()\n",
        "\n",
        "choices = random.sample([json.loads(l) for l in open(VAL_PATH)], VAL_SAMPLES)\n",
        "reqs = [InferRequest(messages=[{'role':'user','content':f\"<image>{c['messages'][0]['content'].replace('<image>','').strip()}\"}],\n",
        "                     images=[c['images'][0]]) for c in choices]\n",
        "\n",
        "for c, r in zip(choices, engine.infer(reqs, rcfg)):\n",
        "    question = c['messages'][0]['content'].replace('<image>', '').strip()\n",
        "    real_answer = c['messages'][1]['content']\n",
        "    pred_answer = r.choices[0].message.content\n",
        "\n",
        "    print(\"\\nQ:\", question)\n",
        "    display(Image.open(c['images'][0]).resize((256,256)))\n",
        "    print(\"Pred:\", pred_answer, \"\\nReal:\", real_answer)"
      ],
      "metadata": {
        "id": "jxvE6nQk-Q7F"
      },
      "id": "jxvE6nQk-Q7F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submitting to the competition\n",
        "To submit this model you have to add a new file named submission_task1.py in the root of your submission repo and need to edit that file with your details following the instructiosn at https://github.com/simula/MediaEval-Medico-2025/blob/main/README.md#-submission-system.\n",
        "\n"
      ],
      "metadata": {
        "id": "WxJ2Adz5_1L3"
      },
      "id": "WxJ2Adz5_1L3"
    },
    {
      "cell_type": "markdown",
      "id": "7d13b826",
      "metadata": {
        "id": "7d13b826"
      },
      "source": [
        "\n",
        "## üß† Tips & Tuning\n",
        "- If you hit **CUDA OOM**:\n",
        "  - Lower `per_device_train_batch_size` to 2 (or 1) and increase `gradient_accumulation_steps`.\n",
        "  - Lower `max_length` to 384 or 256.\n",
        "  - Ensure `freeze_vit=true` and `bnb` 4-bit is enabled.\n",
        "- If training is too slow, reduce dataset size temporarily for prototyping.\n",
        "- Increase `num_train_epochs` to 2‚Äì3 for better results if time allows.\n",
        "- For different VLMs, change `--model` to any supported multimodal model (see SWIFT docs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2bee7e",
      "metadata": {
        "id": "6e2bee7e"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ You‚Äôre done!\n",
        "You can now use your pushed model in other notebooks or pipelines, or extend this setup for **Subtask 2** (explanations) by adding structured outputs (text / visual evidence). Good luck! üçÄ\n",
        "\n",
        "\n",
        "Dont hesitate to contact the organizers for any questiosn or help.\n",
        "https://github.com/simula/MediaEval-Medico-2025/blob/main/README.md#-organizers\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
